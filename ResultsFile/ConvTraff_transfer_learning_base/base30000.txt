Loading dataset from dataset_12_1_1_1_30000_mul_10000.pickle...
Training set (30000, 31, 12, 3) (30000, 31, 1, 3)
Validation set (10000, 31, 12, 3) (10000, 31, 1, 3)
Test set (10000, 31, 12, 3) (10000, 31, 1, 3)
Building model...
Epoch 1/20
429/429 - 643s - loss: 3762924.0000 - mean_absolute_error: 246.6191 - mean_absolute_percentage_error: 7812759.0000 - mean_squared_error: 107532.8906 - root_mean_squared_error: 327.9221 - val_loss: 341222336.0000 - val_mean_absolute_error: 1508.4130 - val_mean_absolute_percentage_error: 424821952.0000 - val_mean_squared_error: 9759044.0000 - val_root_mean_squared_error: 3123.9468 - 643s/epoch - 1s/step
Epoch 2/20
429/429 - 606s - loss: 2050154.0000 - mean_absolute_error: 189.5566 - mean_absolute_percentage_error: 8954693.0000 - mean_squared_error: 58583.7734 - root_mean_squared_error: 242.0408 - val_loss: 6277462.5000 - val_mean_absolute_error: 338.0020 - val_mean_absolute_percentage_error: 310717056.0000 - val_mean_squared_error: 179547.0781 - val_root_mean_squared_error: 423.7299 - 606s/epoch - 1s/step
Epoch 3/20
429/429 - 584s - loss: 560450.1250 - mean_absolute_error: 90.9999 - mean_absolute_percentage_error: 6573335.5000 - mean_squared_error: 16017.4492 - root_mean_squared_error: 126.5601 - val_loss: 535583.8750 - val_mean_absolute_error: 83.4001 - val_mean_absolute_percentage_error: 253674288.0000 - val_mean_squared_error: 15321.9854 - val_root_mean_squared_error: 123.7820 - 584s/epoch - 1s/step
Epoch 4/20
429/429 - 585s - loss: 273540.4062 - mean_absolute_error: 65.1512 - mean_absolute_percentage_error: 6937679.0000 - mean_squared_error: 7821.6704 - root_mean_squared_error: 88.4402 - val_loss: 491141.8750 - val_mean_absolute_error: 82.2798 - val_mean_absolute_percentage_error: 233944128.0000 - val_mean_squared_error: 14050.3604 - val_root_mean_squared_error: 118.5342 - 585s/epoch - 1s/step
Epoch 5/20
429/429 - 585s - loss: 248652.4219 - mean_absolute_error: 61.6229 - mean_absolute_percentage_error: 8055979.0000 - mean_squared_error: 7114.6665 - root_mean_squared_error: 84.3485 - val_loss: 481609.4062 - val_mean_absolute_error: 72.3214 - val_mean_absolute_percentage_error: 249307440.0000 - val_mean_squared_error: 13780.7549 - val_root_mean_squared_error: 117.3915 - 585s/epoch - 1s/step
Epoch 6/20
429/429 - 585s - loss: 201880.3438 - mean_absolute_error: 54.4325 - mean_absolute_percentage_error: 7102547.5000 - mean_squared_error: 5771.1274 - root_mean_squared_error: 75.9679 - val_loss: 442097.8125 - val_mean_absolute_error: 72.3447 - val_mean_absolute_percentage_error: 238063424.0000 - val_mean_squared_error: 12649.6182 - val_root_mean_squared_error: 112.4705 - 585s/epoch - 1s/step
Epoch 7/20
429/429 - 585s - loss: 200535.9375 - mean_absolute_error: 54.1679 - mean_absolute_percentage_error: 7814364.0000 - mean_squared_error: 5733.9590 - root_mean_squared_error: 75.7229 - val_loss: 479322.5625 - val_mean_absolute_error: 71.9890 - val_mean_absolute_percentage_error: 246398320.0000 - val_mean_squared_error: 13715.7998 - val_root_mean_squared_error: 117.1145 - 585s/epoch - 1s/step
Epoch 8/20
429/429 - 584s - loss: 191727.5156 - mean_absolute_error: 52.8360 - mean_absolute_percentage_error: 7246605.0000 - mean_squared_error: 5481.6748 - root_mean_squared_error: 74.0383 - val_loss: 463818.1875 - val_mean_absolute_error: 71.1331 - val_mean_absolute_percentage_error: 246642192.0000 - val_mean_squared_error: 13271.7227 - val_root_mean_squared_error: 115.2030 - 584s/epoch - 1s/step
Epoch 9/20
429/429 - 586s - loss: 188254.6250 - mean_absolute_error: 52.3571 - mean_absolute_percentage_error: 7436338.0000 - mean_squared_error: 5382.0933 - root_mean_squared_error: 73.3628 - val_loss: 457614.1875 - val_mean_absolute_error: 70.9698 - val_mean_absolute_percentage_error: 245845168.0000 - val_mean_squared_error: 13094.0918 - val_root_mean_squared_error: 114.4294 - 586s/epoch - 1s/step
Epoch 10/20
429/429 - 614s - loss: 191176.6250 - mean_absolute_error: 52.7141 - mean_absolute_percentage_error: 7757097.0000 - mean_squared_error: 5465.1318 - root_mean_squared_error: 73.9265 - val_loss: 459111.5312 - val_mean_absolute_error: 70.9402 - val_mean_absolute_percentage_error: 246060960.0000 - val_mean_squared_error: 13136.9570 - val_root_mean_squared_error: 114.6166 - 614s/epoch - 1s/step
Epoch 11/20
429/429 - 739s - loss: 189006.6875 - mean_absolute_error: 52.2970 - mean_absolute_percentage_error: 6951176.5000 - mean_squared_error: 5404.8105 - root_mean_squared_error: 73.5174 - val_loss: 457422.7500 - val_mean_absolute_error: 70.8987 - val_mean_absolute_percentage_error: 245258416.0000 - val_mean_squared_error: 13088.7168 - val_root_mean_squared_error: 114.4059 - 739s/epoch - 2s/step
Epoch 12/20
429/429 - 680s - loss: 189376.7188 - mean_absolute_error: 52.4473 - mean_absolute_percentage_error: 8619721.0000 - mean_squared_error: 5412.8027 - root_mean_squared_error: 73.5718 - val_loss: 457970.5938 - val_mean_absolute_error: 70.9556 - val_mean_absolute_percentage_error: 245754576.0000 - val_mean_squared_error: 13104.3271 - val_root_mean_squared_error: 114.4741 - 680s/epoch - 2s/step
Epoch 13/20
429/429 - 683s - loss: 191157.6719 - mean_absolute_error: 52.6291 - mean_absolute_percentage_error: 6369879.5000 - mean_squared_error: 5463.1338 - root_mean_squared_error: 73.9130 - val_loss: 455947.8750 - val_mean_absolute_error: 70.8779 - val_mean_absolute_percentage_error: 245725376.0000 - val_mean_squared_error: 13046.3838 - val_root_mean_squared_error: 114.2208 - 683s/epoch - 2s/step
Epoch 14/20
429/429 - 673s - loss: 189607.9844 - mean_absolute_error: 52.4662 - mean_absolute_percentage_error: 8327910.0000 - mean_squared_error: 5420.5708 - root_mean_squared_error: 73.6245 - val_loss: 454838.6250 - val_mean_absolute_error: 70.9212 - val_mean_absolute_percentage_error: 245327536.0000 - val_mean_squared_error: 13014.6133 - val_root_mean_squared_error: 114.0816 - 673s/epoch - 2s/step
Epoch 15/20
429/429 - 589s - loss: 189890.7344 - mean_absolute_error: 52.3038 - mean_absolute_percentage_error: 7368368.0000 - mean_squared_error: 5430.0815 - root_mean_squared_error: 73.6891 - val_loss: 461250.6562 - val_mean_absolute_error: 71.0130 - val_mean_absolute_percentage_error: 246539328.0000 - val_mean_squared_error: 13198.2451 - val_root_mean_squared_error: 114.8836 - 589s/epoch - 1s/step
Epoch 16/20
429/429 - 585s - loss: 188954.0156 - mean_absolute_error: 52.3826 - mean_absolute_percentage_error: 7616137.0000 - mean_squared_error: 5401.4209 - root_mean_squared_error: 73.4944 - val_loss: 460731.8125 - val_mean_absolute_error: 71.0559 - val_mean_absolute_percentage_error: 246713104.0000 - val_mean_squared_error: 13183.3271 - val_root_mean_squared_error: 114.8187 - 585s/epoch - 1s/step
Epoch 17/20
429/429 - 585s - loss: 188432.1094 - mean_absolute_error: 52.4102 - mean_absolute_percentage_error: 8836318.0000 - mean_squared_error: 5388.6514 - root_mean_squared_error: 73.4074 - val_loss: 459362.4688 - val_mean_absolute_error: 70.9543 - val_mean_absolute_percentage_error: 246876608.0000 - val_mean_squared_error: 13144.0771 - val_root_mean_squared_error: 114.6476 - 585s/epoch - 1s/step
Epoch 18/20
429/429 - 586s - loss: 189877.0625 - mean_absolute_error: 52.4177 - mean_absolute_percentage_error: 5727820.5000 - mean_squared_error: 5427.8496 - root_mean_squared_error: 73.6739 - val_loss: 458580.4688 - val_mean_absolute_error: 70.9481 - val_mean_absolute_percentage_error: 246065136.0000 - val_mean_squared_error: 13121.8076 - val_root_mean_squared_error: 114.5505 - 586s/epoch - 1s/step
Epoch 19/20
429/429 - 585s - loss: 189068.7344 - mean_absolute_error: 52.3542 - mean_absolute_percentage_error: 7889320.5000 - mean_squared_error: 5408.2090 - root_mean_squared_error: 73.5405 - val_loss: 460543.1250 - val_mean_absolute_error: 70.9993 - val_mean_absolute_percentage_error: 246398896.0000 - val_mean_squared_error: 13178.0029 - val_root_mean_squared_error: 114.7955 - 585s/epoch - 1s/step
Epoch 20/20
429/429 - 586s - loss: 191981.9219 - mean_absolute_error: 52.8047 - mean_absolute_percentage_error: 7350223.5000 - mean_squared_error: 5487.5454 - root_mean_squared_error: 74.0780 - val_loss: 461240.4688 - val_mean_absolute_error: 71.0609 - val_mean_absolute_percentage_error: 246618256.0000 - val_mean_squared_error: 13197.9268 - val_root_mean_squared_error: 114.8822 - 586s/epoch - 1s/step
Filename: /home/uwicore/Documentos/Redes-neuronales/ConvTraff_transfer_learning_base/utils.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
   183    666.2 MiB    666.2 MiB           1   @profile
   184                                         def compile_and_fit(model, train_set,train_labels,valid_set, valid_labels, initial_learning_rate, decay_steps, 
   185                                                     decay_rate,gradient_clip,batch, max_epochs = 20):
   186                                         
   187    666.2 MiB      0.0 MiB           1       log_dir = "logs/fit/" + datetime.datetime.now().strftime("%Y%m%d-%H%M%S")
   188    666.2 MiB      0.0 MiB           2       tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1,
   189    666.2 MiB      0.0 MiB           1           write_images=True, write_steps_per_second=True,embeddings_freq=1)
   190                                         
   191    666.2 MiB      0.0 MiB           1       csv_logger = keras.callbacks.CSVLogger('logs/ConvTraff_transfer_learning_base.csv',append =True)
   192                                         
   193    666.2 MiB      0.0 MiB           1       checkpoint_filepath = 'savedModel/ConvTraff_transfer_learning_base/model.{epoch:02d}.ckpt'
   194    666.2 MiB      0.0 MiB           2       model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(
   195    666.2 MiB      0.0 MiB           1           filepath=checkpoint_filepath,
   196    666.2 MiB      0.0 MiB           1           save_weights_only=False,
   197    666.2 MiB      0.0 MiB           1           monitor='mean_absolute_percentage_error',
   198    666.2 MiB      0.0 MiB           1           mode='auto',
   199    666.2 MiB      0.0 MiB           1           save_freq='epoch',
   200    666.2 MiB      0.0 MiB           1           save_best_only=False)
   201                                         
   202    666.2 MiB      0.0 MiB           2       learning_rate = tf.keras.optimizers.schedules.ExponentialDecay(
   203    666.2 MiB      0.0 MiB           1           initial_learning_rate, decay_steps, decay_rate, staircase=True)
   204                                         
   205    667.2 MiB      0.0 MiB           2       model.compile(loss=l2loss,#Â¡tf.losses.MeanAbsoluteError(),
   206    666.2 MiB      0.0 MiB           1                       optimizer= keras.optimizers.SGD(learning_rate,clipvalue = gradient_clip,momentum = 0.9),
   207    667.2 MiB      0.2 MiB           2                       metrics=[tf.keras.metrics.MeanAbsoluteError(), 
   208    666.5 MiB      0.0 MiB           1                       tf.keras.metrics.MeanAbsolutePercentageError(),
   209    666.5 MiB      0.0 MiB           1                       tf.keras.metrics.MeanSquaredError(),
   210    667.2 MiB      0.7 MiB           1                       tf.keras.metrics.RootMeanSquaredError()])
   211                                         
   212   2568.0 MiB   1900.8 MiB           2       history = model.fit(train_set,train_labels,validation_data = (valid_set, valid_labels), 
   213    667.2 MiB      0.0 MiB           1           batch_size = batch, epochs= max_epochs,shuffle=True,verbose =2,
   214    667.2 MiB      0.0 MiB           1           callbacks=[csv_logger,model_checkpoint_callback])#,callbacks=[tensorboard_callback]) #, callbacks=[model_checkpoint_callback]
   215   2568.0 MiB      0.0 MiB           1       return history


143/143 - 26s - loss: 343056.1250 - mean_absolute_error: 61.3258 - mean_absolute_percentage_error: 14.3358 - mean_squared_error: 9859.2725 - root_mean_squared_error: 99.2939 - 26s/epoch - 183ms/step
Model: "model"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_2 (InputLayer)        [(None, None, 12, 3)]     0         
                                                                 
 batch_normalization (BatchN  (None, None, 12, 3)      12        
 ormalization)                                                   
                                                                 
 zero_padding2d (ZeroPadding  (None, None, 12, 32)     0         
 2D)                                                             
                                                                 
 resnet (Resnet)             (None, None, 12, 32)      18752     
                                                                 
 resnet_1 (Resnet)           (None, None, 12, 32)      18752     
                                                                 
 resnet_2 (Resnet)           (None, None, 12, 32)      18752     
                                                                 
 zero_padding2d_1 (ZeroPaddi  (None, None, 12, 64)     0         
 ng2D)                                                           
                                                                 
 resnet_3 (Resnet)           (None, None, 12, 64)      74368     
                                                                 
 resnet_4 (Resnet)           (None, None, 12, 64)      74368     
                                                                 
 resnet_5 (Resnet)           (None, None, 12, 64)      74368     
                                                                 
 zero_padding2d_2 (ZeroPaddi  (None, None, 12, 96)     0         
 ng2D)                                                           
                                                                 
 resnet_6 (Resnet)           (None, None, 12, 96)      166848    
                                                                 
 resnet_7 (Resnet)           (None, None, 12, 96)      166848    
                                                                 
 resnet_8 (Resnet)           (None, None, 12, 96)      166848    
                                                                 
 global_average_pooling2d (G  (None, 96)               0         
 lobalAveragePooling2D)                                          
                                                                 
 dense (Dense)               (None, 2048)              198656    
                                                                 
 dropout (Dropout)           (None, 2048)              0         
                                                                 
 dense_1 (Dense)             (None, 1024)              2098176   
                                                                 
 dense_2 (Dense)             (None, 1)                 1025      
                                                                 
=================================================================
Total params: 3,077,773
Trainable params: 3,075,463
Non-trainable params: 2,310
_________________________________________________________________
Evaluation in test_set:
[343056.125, 61.32581329345703, 14.33578109741211, 9859.2724609375, 99.29386901855469]
